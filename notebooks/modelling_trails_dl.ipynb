{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Trails - Deep Learning\n",
    "\n",
    "In this notebook, we will train various deep learning models using PyTorch. We will compare their performance and select the best model for forecasting sales quantity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "from src.utils.data_ingestion import download_dataset, extract_dataset, load_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dataset already exists in the data directory.\n",
      "INFO:root:Dataset loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Holiday_Indicator</th>\n",
       "      <th>Past_Purchase_Trends</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Competitor_Price</th>\n",
       "      <th>Sales_Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26/09/24</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>BrandA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>462.30</td>\n",
       "      <td>33.96</td>\n",
       "      <td>359.45</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/09/24</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>BrandA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>66.3</td>\n",
       "      <td>321.28</td>\n",
       "      <td>24.76</td>\n",
       "      <td>49.47</td>\n",
       "      <td>370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26/09/24</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>BrandA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>74.85</td>\n",
       "      <td>32.19</td>\n",
       "      <td>245.11</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26/09/24</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>BrandA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>469.12</td>\n",
       "      <td>43.68</td>\n",
       "      <td>144.08</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22/09/24</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>BrandA</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>93.5</td>\n",
       "      <td>221.76</td>\n",
       "      <td>36.79</td>\n",
       "      <td>478.07</td>\n",
       "      <td>470.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date    Category   Brand  Day_of_Week  Holiday_Indicator  \\\n",
       "0  26/09/24  Automotive  BrandA            3                  0   \n",
       "1  26/09/24  Automotive  BrandA            3                  0   \n",
       "2  26/09/24  Automotive  BrandA            3                  0   \n",
       "3  26/09/24  Automotive  BrandA            3                  0   \n",
       "4  22/09/24  Automotive  BrandA            6                  1   \n",
       "\n",
       "   Past_Purchase_Trends   Price  Discount  Competitor_Price  Sales_Quantity  \n",
       "0                  17.9  462.30     33.96            359.45           227.0  \n",
       "1                  66.3  321.28     24.76             49.47           370.0  \n",
       "2                  14.4   74.85     32.19            245.11           299.0  \n",
       "3                  34.7  469.12     43.68            144.08           426.0  \n",
       "4                  93.5  221.76     36.79            478.07           470.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_dataset()\n",
    "extract_dataset()\n",
    "\n",
    "df = load_data(\"Data/Dataset/Train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                      0\n",
       "Category                  0\n",
       "Brand                     0\n",
       "Day_of_Week               0\n",
       "Holiday_Indicator         0\n",
       "Past_Purchase_Trends      0\n",
       "Price                     0\n",
       "Discount                  0\n",
       "Competitor_Price          0\n",
       "Sales_Quantity          464\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14415, 10), (3604, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "\n",
    "train_size = int(len(df) * 0.8)\n",
    "val_size = len(df) - train_size\n",
    "train_data, val_data = df.iloc[:train_size], df.iloc[train_size:]\n",
    "\n",
    "# View the shapes\n",
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Preprocessor for Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Day_of_Week',\n",
       "  'Holiday_Indicator',\n",
       "  'Past_Purchase_Trends',\n",
       "  'Price',\n",
       "  'Discount',\n",
       "  'Competitor_Price',\n",
       "  'Sales_Quantity'],\n",
       " ['Date', 'Category', 'Brand'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the columns into numerical and categorical columns\n",
    "num_columns =  list(df.select_dtypes(include=\"number\").columns)\n",
    "col_columns = list(df.select_dtypes(exclude=\"number\").columns)\n",
    "\n",
    "num_columns, col_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical transformer \n",
    "numerical_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define categorical transformer\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create preprocessor\n",
    "feature_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_transformer', numerical_transformer, num_columns),\n",
    "        ('cat_transformer', categorical_transformer, col_columns)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms the data\n",
    "train_features = feature_preprocessor.fit_transform(train_data)\n",
    "val_features = feature_preprocessor.transform(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target transformer\n",
    "target_transformer = Pipeline(\n",
    "   steps=[\n",
    "        ('target_scaler', StandardScaler())\n",
    "    ]\n",
    "    )\n",
    "\n",
    "# Transforms the target data\n",
    "\n",
    "train_target = target_transformer.fit_transform(np.array(train_data[\"Sales_Quantity\"]).reshape(-1, 1)).squeeze()\n",
    "val_target = target_transformer.transform(np.array(val_data[\"Sales_Quantity\"]).reshape(-1, 1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14415,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20829116,  0.80290733,  0.30084375,  1.19890114,  1.51003914])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating windowed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windowed_dataset(features: np.ndarray, target: np.ndarray, window_size: int = 7, forecast_steps: int = 1):\n",
    "    \"\"\"\n",
    "    Creates a windowed dataset for a given feature and target array.\n",
    "    \n",
    "    Args:\n",
    "        features (np.ndarray): Input features.\n",
    "        target (np.ndarray): Target values.\n",
    "        window_size (int): Size of the window.\n",
    "        forecast_steps (int): Number of steps to forecast ahead.\n",
    "        \n",
    "    Returns:\n",
    "        X (np.ndarray): Windowed features.\n",
    "        y (np.ndarray): Windowed target values.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(features) - window_size - forecast_steps + 1):\n",
    "        X.append(features[i:i + window_size])\n",
    "        y.append(target[i + window_size:i + window_size + forecast_steps])\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_windowed_dataset(np.array(train_features), train_target, window_size=7, forecast_steps=1)\n",
    "X_val, y_val = create_windowed_dataset(np.array(val_features),val_target, window_size=7, forecast_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14408, 7, 358), (14408, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "class SalesDataset(Dataset):\n",
    "    def __init__(self, features: np.ndarray, target: np.ndarray):\n",
    "        super().__init__()\n",
    "        self.features =features \n",
    "        self.target = target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.target[idx], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datset and Dataloaders\n",
    "\n",
    "train_dataset = SalesDataset(X_train, y_train)\n",
    "val_dataset = SalesDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 358]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataset:\n",
    "    print(X.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Deep Learning models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a script for training the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader, loss_fn: nn.Module, optimizer: torch.optim.Optimizer, epochs: int = 10):\n",
    "    \"\"\" Trains the model on the dataset\n",
    "        Args:  \n",
    "            model (nn.Module): model to train the model\n",
    "            train_loader (DataLoader): Training DataLoader\n",
    "            val_loader (DataLoader): Validation DataLoader\n",
    "            loss_fn (nn.Module): Loss function\n",
    "            optimizer (torch.optim.Optimizer): Optimizer\n",
    "            epochs (int): Number of epochs to train the model\n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs: \"):\n",
    "        train_loss, test_loss = 0.0, 0.0\n",
    "\n",
    "        model.train()\n",
    "        ### Training loss\n",
    "        for X, y in tqdm(train_loader, desc=\"Training...\", leave=False):\n",
    "            outputs = model(X)\n",
    "            loss = loss_fn(outputs, y)\n",
    "            train_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #### Testing time\n",
    "        model.eval()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for X, y in tqdm(val_loader, desc=\"Evaluating...\", leave=False):\n",
    "                outputs = model(X)\n",
    "                test_loss += loss_fn(outputs, y).item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        test_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch: {epoch + 1}/{epochs} | Train Loss: {np.sqrt(train_loss):.4f} | Test Loss : {np.sqrt(test_loss):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'input_size' : train_features.shape[1],\n",
    "    'hidden_size': 128,\n",
    "    'num_layers': 2,\n",
    "    'batch_size' : 32,\n",
    "    'forecast_steps': 1,\n",
    "    'num_epochs': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, num_layers, batch_size, forecast_steps):\n",
    "            super().__init__()\n",
    "            self.hidden_size = hidden_size\n",
    "            self.num_layers = num_layers\n",
    "            self.batch_size = batch_size\n",
    "            self.forecast_steps = forecast_steps\n",
    "            self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.fc = nn.Linear(hidden_size, forecast_steps)\n",
    "\n",
    "        def forward(self, x):\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "            out, _ = self.lstm(x, (h0, c0))\n",
    "            out = self.relu(out)\n",
    "            out = self.fc(out[:, -1, :])\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  10%|█         | 1/10 [00:07<01:04,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 | Train Loss: 1.0007 | Test Loss : 0.9909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 2/10 [00:17<01:10,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10 | Train Loss: 0.9988 | Test Loss : 0.9923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  30%|███       | 3/10 [00:26<01:03,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10 | Train Loss: 0.9918 | Test Loss : 0.9936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 4/10 [00:33<00:48,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10 | Train Loss: 0.9763 | Test Loss : 0.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 5/10 [00:40<00:38,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10 | Train Loss: 0.9549 | Test Loss : 1.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 6/10 [00:47<00:30,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10 | Train Loss: 0.9227 | Test Loss : 1.0524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  70%|███████   | 7/10 [00:56<00:24,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10 | Train Loss: 0.8842 | Test Loss : 1.0685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 8/10 [01:03<00:15,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10 | Train Loss: 0.8402 | Test Loss : 1.1203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  90%|█████████ | 9/10 [01:10<00:07,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10 | Train Loss: 0.7883 | Test Loss : 1.1663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 10/10 [01:16<00:00,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10 | Train Loss: 0.7517 | Test Loss : 1.1876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the model and train it\n",
    "\n",
    "model = LSTMModel(input_size=hyperparams['input_size'], num_layers =hyperparams['num_layers'], hidden_size=hyperparams['hidden_size'], batch_size=hyperparams['batch_size'], forecast_steps=hyperparams['forecast_steps'])\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train(model, train_loader, val_loader, loss_fn, optimizer, epochs=hyperparams['num_epochs'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecommerce-forecasting-competition-ukqjLbNQ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
